[[sac_training]]

|算法库|主要功能|数学公式|源码位置|
|---|---|---|---|
|PyTorch|深度学习框架|自动微分、张量运算|全项目|
|SAC|强化学习算法|熵正则化、双Q网络|sac_agent.py|
|Transformer|注意力机制|自注意力、多头注意力|attention.py|
|Reeds-Shepp|路径规划|圆弧-直线组合|reeds_shepp.py|
|Shapely|几何计算|多边形相交、面积计算|car_parking_base.py|
|NumPy|数值计算|矩阵运算、随机采样|全项目|
|Matplotlib|可视化|绘图、动画|训练脚本|
*****
1. Pytorch
2. SAC
	- SAC算法核心流程与数学公式
		1. 算法核心思想
			最大化奖励的同时最大化策略熵（鼓励探索）。
			双Q网络防止Q值高估，目标网络提升稳定性。
			自动温度调整，平衡探索与利用。
		2. 核心数学
			- 策略目标
				最大化：$J(π)=E_{(s_{t},a_{t})}∼ρ_{π}[r(s_{t},a_{t})+αH(π(⋅∣s_{t}))])$
				其中$H(π(⋅∣s_{t}))=−E_{a_{t}}∼πlog⁡π(a_{t}∣s_{t})$为熵。
			- Q函数目标
				$J_{Q}(θ)=E_{(s_{t},a_{t})∼D}[ \frac{1}{2}(Q_{θ}(s_{t},a_{t})−(r_{t}+γE_{a_{t+1}∼π}[Q_{θˉ}(s_{t+1},a_{t+1})−αlog⁡π(a_{t+1}∣s_{t+1})]))^2]$
			- 策略网络目标
				$J_{π​}(ϕ)=E_{s_t​∼D,a_{t}​∼π_{ϕ}​​}[αlogπ_{ϕ}(a_{t}​∣s_{t}​)−Q_{θ​}(s_{t}​,a_{t}​)]$
			- 温度参数目标
				$J(α)=E_{a_{t}​∼π​}[−αlogπ(a_{t}​∣s_{t}​)−αH_{target}]​$
		3. 源码实现流程与方法说明
			- 主要库
				torch：神经网络与自动微分
				torch.optim：优化器
				torch.distributions.Normal：高斯策略分布
				numpy：数值计算
				