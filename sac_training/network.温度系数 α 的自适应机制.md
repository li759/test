[[network]]
1. 为什么 α 要自适应  
	在最大熵 RL（包括 SAC）里，目标函数里有一项 −α 𝔼[log π(a|s)]。
	- α 太大 → 策略被迫保持高熵，过度探索，回报下降。
	- α 太小 → 策略趋向确定性，失去探索，易陷入局部最优。  
	    手动调 α 非常痛苦，于是 SAC 把 α 也当成**可训练参数**，让算法自己把策略的**平均熵**拉到用户设定的“目标熵”附近。
2. 数学表述
	1. 优化目标（整体）：  
	    max_π 𝔼[ Σ_t r_t + α ℋ(π(·|s_t)) ]  
	    其中 ℋ(π) = −𝔼_{a∼π}[log π(a|s)]。
	2. 把 α 也纳入优化：  
	    min_{α>0} 𝔼[ α ( −log π(a|s) − target_entropy ) ]  
	    等价于  
	    min_{α>0} α · ( 𝔼[ −log π ] − target_entropy ).
	3. 目标熵 target_entropy 的选取  
	    连续动作空间：target_entropy = −dim(A)  
	    离散动作空间：target_entropy = −log |A|  
	    （经验值，保证策略不会太随机也不会太集中。）
